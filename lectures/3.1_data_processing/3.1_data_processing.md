# 3.1 Data Processing

## Learning Objectives
- Carry out an EO workflow on a cloud platform
- Select suitable data
- Chain processes to form an EO processing chain/workflow
- Visualize the results

## Introdcution
In this lecture we are going to combine the knowledge and hands-on experience we have gathered so far to create a full EO workflow on a cloud platform.
We will  
- define a research question,
- choose and load the necessary data sources, 
- define the data cube to our needs, 
- use functions to process the data, 
- visualize the result
- and track the resources we are consuming on the platform.

## Case Study: Snow Cover in the Alps

#### Video: Advantages of a workflow on a cloud platform

### Research Question
Snow serves as a water reservoir and is thus important for any hydrological management activity, such as irrigation planning, drink water supply or hydro power generation. Knowing precisely, when and where snow is present is a critical source of information for these acitivities. Satellite earth observation plays an important role in describing the snow cover, both globally and in local mountain ranges. Due to it's ability to sense spatially covering it and repeatedly. Our goal is to create a time series of the snow covered area of the catchment of interest. We will use this time series to compare it to the run off at the main outlet of the catchment. And study the relationship between snow dynamics and runoff.

### Approach
In this exercise we are going to derive the snow cover in an alpine catchment using Sentinel-2 data. Sentinel-2 carries an optical sensor, it is measuring the reflected light of the earths surface in differenct wavelenghts. At a 10m spatial resolution and at a 6 day repeat rate. We are using the X and X band to calculate the Normalized Difference Snow Index (NDSI). It is calculated as follows: XXX. It makes use of the XXX phenomenon and expresses it as a formula. The result is a value between -1 and 1. The higher the value is, the more probable it is that the surface is covered with snow. In order to create a binary snow map we apply a threshold of NDSI < 0.4. This is a commonly used value for discriminating snowcovered and snow free areas. Then we spatially aggregate the snow free and snow covered pixels in the catchment area by summing them up. In order to get the snow covered area of the catchment we multiply the number of snow covered pixels by 10 m, which is the resolution of the Sentinel-2 data we are using. Additionally, we have to deal with cloud cover. We use the Sentinel-2 cloud mask that is provided with the data and exclude all images that have a cloud cover over XX % in our study area. Ideally we should fill the gaps the clouds generate, since they are introducing uncertainty. Nevertheless, for a first try our approach should be good enough to get a general idea about the snow cover in our area of interest. In the end we receive a time series with the snow covered area in the catchment. 
The approach we are using is very basic. There are many assumptions and simplifications involved. A critical analysis of the workflow and possible improvements follows in Section [3.3 Validation](https://github.com/EO-College/cubes-and-clouds/blob/main/lectures/3.3_validation/3.3_validation.md#critically-analyse-a-workflow)


### Excursion: Using multiple Data Sources on a cloud platform. Data Fusion
What is to be considered when doing data fusion:
- Extent (time, space, bands)
- Resolution (time, space, bands; what is the information in the bands - is it comparable...)
- Dimensionality
- illustrate this with data cube models

How to solve this on a cloud platform!
- Checking the extent of the collections
- Aligning the extent of the collections
- Aligning the resolution of the collections (aggregating, resampling, reducing)

### Workflow Description
- Describe the functions we are using one by one, and what happens to the data cube.
- embed process graph as html

- get data:
  - `load_collection()`
- ndsi:
  - `filter_bands()`, `reduce_dimension()`
  - creates a -1 to 1 map, 1 signifies high probability of snow
- create binary snow classification (by threshold):
  - `mask()`, `gt()`
  - create a binary snow classification: 0 = no snow, 1 = snow
- cloud masking:
  - `mask()`
  - Apply the mask to the binary snow map: 0 = no snow, 1 = snow, NA = cloud
- snow covered area:
  - `aggregate_spatial()`, `sum()`
  - sum up all pixels, the sum corresponds to the snow covered area (*10m2), divide by area of catchment to get percentage
  - save as json time series: sca (or merge cubes with cld and save then)
- cloud percentage:
  -  aggregate_spatial(), count() or sum()
  -  count the number of NA pixels, divide by the total number of pixels = cloud percentage
  -  save as json time series: cld (or merge cubes with sca and save then)
- filter timeseries according to cloud coverage:
  - join the two timeseries by date, filter the dates that have cloud coverages > 30%
- compare to runoff time series:
  - load the runoff timeseries and plot the two time series against each other

### Out of Scope: Excursion: How openEO functions are defined (input, arguments, output) 
This should be moved to 2.3 Data Access or removed completely


## Tracking resources
- Explain Basics of resource usage on cloud platforms
- Point to Scaling Lesson: There we can go more into details

## Hands On Exercise
Now we have covered the most important topics of our use case in theory. Let's move on to produce some results!

**Disclaimer: The applied workflow is a simple approach used for educational reasons to learn how to use EO cloud platforms**

#### Exercise: Snow Cover Area Time Series

## Quiz
### Exercise Part
- What is the city at the outlet of the catchment? a) Meran, b) Innsbruck, c) Grenoble
- How many images are available in the time range?
- How many pixels are in the data cube?** (time * x * y * bands)
- How many pixels are we looking at
- How many resources did we use up to this state
- How many snow covered pixels are there across all time steps?
- At which time step is the maximum snow cover reached? 
- What is the number of snow covered pixels on that date?
- What does that represent in area (km2)?
- How is the relation between snow cover and runoff?
  - Show different diagrams, the should choose the correct one
- Explain how to avoid unneccesary waste of resources on cloud platforms

